My understanding of TCP Offload:
	Usually, the processing of TCP/IP will be done by the stack. Since ethernet speeds have gone past 100MB and reached 10GB, it will be a huge burden on the CPU to process TCP/IP packets at such a large rate. So Offloading was introduced. Some bottlenecks identified were
Reassembling of out-of-order packets,
memory copies,
interrupts etc.
In high network traffic, the CPU has to dedicate most of its time to process network packets than processing the applications. TOE is the solution which limits the processing required by the CPU. TOE is embedded in the NIC or host bus adapter. A design would be like the following.
				
						Application
						    | |
						Operating System ( TCP / IP stack )
						    | |
						Hardware ( Traditional NIC with TOE adapter ( TCP/IP, MAC, PHY)

The intention is to reduce the work load of CPU and take the load on the hardware. A TOE can be implemented with a network processor and a firmware or specialized ASIC's. Mostly they offload TCP and IP processing from the host processor. This allows new protocols like iSCSI, Network Attached Storage. 
Before TOE, some OS's did offload by reducing compute intensive tasks to the adapters. One example of a simple offload is the IP Checksum offload. When the speed started increasing, this simple offload was not enough. 
TOE can be implemented in processor based solution or ASIC based solution. Processor based solutions were not fast but allowed more features to be implemented. ASIC based solutions were fast but was not flexible. Today, there are optimized ASIC's using multiple processing engines to provide ASIC like performance. 

Processor based Implementation:
================================
In one of the implementations of TOE, there is a network processor running a RTOS and the traditional MAC/PHY processing. The protocol processing from the host CPU is now offloaded to the network processor running a real time RTOS. This not only offloads the TCP from the host OS's stack, but also anyother protocols that are embedded in the stack of the RTOS provided the hardware has correct hooks to offload.

ASIC based implementation:
===========================
In another implementation, an ASIC is used, where TCP/IP processing is offloaded to performance optimized hardware. But this is not flexible.

Hybrid Implementation:
=======================
There are implementations which take advantage of both. 


Offloading in TCP:
==================
	In places where a TCP session is expected to be up for a long time, the main overhead is the data transmission and reception. The offloading of this type is "data path" offloading. It eliminates TCP/IP overhead in data transmission/reception. The host stack just maintains reponsibilities for other jobs like connection establishment, closing and error handling.

Full offloading means, all the handling is done in the TCP stack in the hardware. Even the connection management tasks is taken from the host processor. In places where connections are frequently expected to go down and come up, full TCP offloading is of big advantage. 

Performance metrics:
=====================
	Advantages of TOE can be measured through throughput, CPU utilization and latency. 
The important measure is the amount of data moved from network buffer to user buffer and back and the number of transactions to move the data. TOE interfaces to the system above the transport layer with a session layer interface. The main advantage is that applications typically read and write in large blocks. In this case, the work load on the host processor is drastically reduced. 

How is data moved between application buffers and TOE buffers:
===============================================================
The data is moved to and from application buffers by hardware DMA engine. 
  
Challenges:
===========
	No standard driver interface for major OS and TOE adaptors. 
	Drivers for TOE are interfacing to OS in proprietary ways.
	It is expensive.

Main advantages:
================
	It frees up the host CPU by doing all the work being done in the TCP/IP stack in the TOE. 
	It saves some data transfers since the cards act on the dayta locally.
	All the host processor needs to do is to open the connection and the TCP Offload Engine ( TOE ) on the NIC and it will take from there.

Path of Data in TOE:
=====================
	It is a process-process layer. Data passed to the TCP Offload enginer comes straight from the application process and thedata delivered from the TOE is ready to be passed to the application process. 
	Direct Data Placement (DDP): Addresses the memory bottleneck problem on receive.
	Direct Data Sourcing (DDS): Addresses the memory bottleneck problem on send.
	CRC Offload: Application layer data integrity check. 
